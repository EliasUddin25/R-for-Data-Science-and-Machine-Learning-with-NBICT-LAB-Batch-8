5+5
23+56
23+56
-> 23+56
data = c(9, 6, 17, 31, 11)
mean(data)
summary(data)
setwd("C:/Users/elias/OneDrive/Data Science and Machine Learning/R-for-Data-Science-and-Machine-Learning-with-NBICT-LAB-Batch-8/RDSML-Day-49 ðŸ‘‰ Multiple Linear Regression in R (Part-2)")
# Multiple Linear Regression
# Importing the dataset
dataset <- read.csv("50_Startups.csv")
# Encoding categorical data
dataset$State <- factor(dataset$State,
levels = c('New York', 'California', 'Florida'),
labels = c(1, 2, 3))
library(caTools)
set.seed(123)
split <- sample.split(dataset$Profit, SplitRatio = 0.8)
training_set <- subset(dataset, split == TRUE)
test_set <- subset(dataset, split == FALSE)
View(dataset)
View(test_set)
View(training_set)
regressor <- lm(formula = Profit ~ R.D.Spend + Administration + Marketing.Spend + State,
data = training_set)
summary(regressor)
# Predicting the Test set results
y_pred <- predict(regressor, test_set)
y_pred
regressor <- lm(formula = Profit ~ R.D.Spend + Administration + Marketing.Spend + State,
data = training_set)
summary(regressor)
regressor <- lm(formula = Profit ~ R.D.Spend + Administration + Marketing.Spend,
data = training_set)
summary(regressor)
regressor <- lm(formula = Profit ~ R.D.Spend + Marketing.Spend,
data = training_set)
summary(regressor)
# Automated Stepwise Backward Elimination
full_model <- lm(Profit ~ ., data = training_set)
summary(full_model)
final_model <- step(full_model, direction = "backward")
summary(final_model)
cor(training_set$R.D.Spend, training_set$Profit, method = 'Pearson')
cor(training_set$R.D.Spend, training_set$Profit, method = 'pearson')
cor.test(training_set$R.D.Spend, training_set$Profit, method = 'pearson')
cor.test(training_set$Marketing.Spend, training_set$Profit, method = 'pearson')
plot(training_set$R.D.Spend, training_set$Profit, method = 'pearson')
plot(final_model)
install.packages("lmtest")
# Checking for the independent of errors/observation/
# install.packages("lmtest")
library(lmtest)
dwtesrt(final_model)
dwtest(final_model)
# Normality of residuals
shapiro.test(rstandard(final_model))
qqnorm(rstandard(final_model))
qqline(rstandard(final_model))
# Checking multicolinearity
library(car)
vif(final_model)
# Homosedasticity assumption
plot(final_model$fitted.values, rstandard(final_model))
abline(h=0, col='red')
bptest(final_model)
